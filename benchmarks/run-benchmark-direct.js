#!/usr/bin/env node

/**
 * 10x Architect Benchmark Runner - Direct Mode
 *
 * This script measures prompts against objective metrics.
 * Enhanced prompts are provided as input (generated by Claude).
 */

const fs = require('fs');
const path = require('path');

// Test prompts and their enhanced versions (generated by Claude)
const benchmarkData = {
  prompts: [
    {
      id: "feature-simple",
      category: "feature",
      complexity: "simple",
      original: "add a search bar to the header",
      enhanced: null // Will be filled by running enhancement
    },
    {
      id: "feature-medium",
      category: "feature",
      complexity: "medium",
      original: "implement user authentication",
      enhanced: null
    },
    {
      id: "feature-complex",
      category: "feature",
      complexity: "complex",
      original: "add a real-time notification system with websockets",
      enhanced: null
    },
    {
      id: "bugfix-simple",
      category: "bugfix",
      complexity: "simple",
      original: "fix the login button not working",
      enhanced: null
    },
    {
      id: "bugfix-medium",
      category: "bugfix",
      complexity: "medium",
      original: "fix the memory leak in the dashboard component",
      enhanced: null
    },
    {
      id: "refactor-simple",
      category: "refactor",
      complexity: "simple",
      original: "refactor the utils file",
      enhanced: null
    },
    {
      id: "refactor-medium",
      category: "refactor",
      complexity: "medium",
      original: "refactor the API module to use async/await",
      enhanced: null
    },
    {
      id: "refactor-complex",
      category: "refactor",
      complexity: "complex",
      original: "refactor the monolithic service into microservices",
      enhanced: null
    },
    {
      id: "docs-simple",
      category: "documentation",
      complexity: "simple",
      original: "add documentation to the auth module",
      enhanced: null
    },
    {
      id: "test-simple",
      category: "testing",
      complexity: "simple",
      original: "add tests for the user service",
      enhanced: null
    }
  ]
};

// Metrics to measure
const metrics = [
  { id: "has_goal", name: "Has Clear Goal", pattern: /(Goal:|GOAL|goal:|We will|objective)/gi },
  { id: "has_north_star", name: "Has North Star", pattern: /(North Star|NORTH STAR|business value|user benefit)/gi },
  { id: "has_constraints", name: "Has Constraints", pattern: /(Do NOT|Don't|CONSTRAINT|must not|avoid)/gi },
  { id: "has_phases", name: "Has Execution Phases", pattern: /(Phase|PHASE|Step \d|\d\.\s+\w|EXECUTION)/gi },
  { id: "has_tdd", name: "Has TDD Instructions", pattern: /(TDD|test.driven|RED.GREEN|write.*test.*first|failing test)/gi },
  { id: "has_docs", name: "Has Documentation Req", pattern: /(document|JSDoc|docstring|README)/gi },
  { id: "has_solid", name: "Has SOLID Principles", pattern: /(SOLID|Single Responsibility|Open.Closed|Liskov|Interface Segregation|Dependency Inversion)/gi },
  { id: "has_edge_cases", name: "Has Edge Cases", pattern: /(edge case|error handling|exception|validate|boundary)/gi },
  { id: "constraint_count", name: "Constraint Count", pattern: /(Do NOT|Don't|must not)/gi, type: "count" },
  { id: "phase_count", name: "Phase Count", pattern: /^\s*\d+[.)]\s+\w/gm, type: "count" }
];

function measureText(text) {
  const results = {};
  let score = 0;
  let maxScore = 0;

  for (const metric of metrics) {
    const matches = text.match(metric.pattern) || [];

    if (metric.type === "count") {
      results[metric.id] = matches.length;
    } else {
      const found = matches.length > 0;
      results[metric.id] = found;
      score += found ? 1 : 0;
      maxScore += 1;
    }
  }

  results.score = score;
  results.maxScore = maxScore;
  results.percentage = ((score / maxScore) * 100).toFixed(1);

  return results;
}

function runBenchmark(enhancedPrompts) {
  console.log('═══════════════════════════════════════════════════════════════');
  console.log('              10x ARCHITECT REAL BENCHMARK RESULTS              ');
  console.log('═══════════════════════════════════════════════════════════════\n');

  const results = [];
  let totalOriginal = 0;
  let totalEnhanced = 0;

  for (let i = 0; i < benchmarkData.prompts.length; i++) {
    const prompt = benchmarkData.prompts[i];
    const enhanced = enhancedPrompts[i];

    const originalMetrics = measureText(prompt.original);
    const enhancedMetrics = measureText(enhanced);

    console.log(`[${i + 1}] ${prompt.original}`);
    console.log(`    Original:  ${originalMetrics.percentage}% (${originalMetrics.score}/${originalMetrics.maxScore})`);
    console.log(`    Enhanced:  ${enhancedMetrics.percentage}% (${enhancedMetrics.score}/${enhancedMetrics.maxScore})`);
    console.log(`    Improvement: +${(enhancedMetrics.percentage - originalMetrics.percentage).toFixed(1)}%\n`);

    totalOriginal += parseFloat(originalMetrics.percentage);
    totalEnhanced += parseFloat(enhancedMetrics.percentage);

    results.push({
      id: prompt.id,
      original: prompt.original,
      originalScore: originalMetrics.percentage,
      enhancedScore: enhancedMetrics.percentage,
      originalMetrics,
      enhancedMetrics,
      enhanced
    });
  }

  const avgOriginal = (totalOriginal / benchmarkData.prompts.length).toFixed(1);
  const avgEnhanced = (totalEnhanced / benchmarkData.prompts.length).toFixed(1);
  const improvement = (avgEnhanced - avgOriginal).toFixed(1);

  console.log('═══════════════════════════════════════════════════════════════');
  console.log('                          SUMMARY                               ');
  console.log('═══════════════════════════════════════════════════════════════\n');
  console.log(`  Average WITHOUT plugin: ${avgOriginal}%`);
  console.log(`  Average WITH plugin:    ${avgEnhanced}%`);
  console.log(`  Average Improvement:    +${improvement}%\n`);

  // Save results
  const output = {
    timestamp: new Date().toISOString(),
    summary: { avgOriginal, avgEnhanced, improvement },
    results
  };

  fs.writeFileSync(
    path.join(__dirname, 'results', 'latest.json'),
    JSON.stringify(output, null, 2)
  );

  console.log('Results saved to benchmarks/results/latest.json');

  return output;
}

// Export for use
module.exports = { benchmarkData, metrics, measureText, runBenchmark };

// If enhanced prompts file exists, run benchmark
const enhancedFile = path.join(__dirname, 'results', 'enhanced-prompts.json');
if (fs.existsSync(enhancedFile)) {
  const enhanced = JSON.parse(fs.readFileSync(enhancedFile, 'utf-8'));
  runBenchmark(enhanced);
}
